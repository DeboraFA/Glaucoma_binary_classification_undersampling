{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ec272",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10968,
     "status": "ok",
     "timestamp": 1655562800010,
     "user": {
      "displayName": "Débora Ferreira",
      "userId": "05060274424742616333"
     },
     "user_tz": 180
    },
    "id": "f95ec272",
    "outputId": "2e3da4fd-4ff5-40b7-85d5-6aefbc6c90af"
   },
   "outputs": [],
   "source": [
    "# !pip install numpy --upgrade\n",
    "# !pip install mahotas\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import mahotas\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from skimage.exposure import is_low_contrast\n",
    "from skimage.filters import gabor_kernel\n",
    "from scipy.stats import kurtosis, skew\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure, feature, color\n",
    "from skimage.feature import hog\n",
    "from scipy import ndimage as ndi\n",
    "from pywt import dwt2\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "from load_data_metrics import load_data, metrics, cv_train, results, data_balanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f14de",
   "metadata": {
    "id": "571f14de"
   },
   "source": [
    "# Features extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094903a",
   "metadata": {
    "id": "f094903a"
   },
   "outputs": [],
   "source": [
    "kernels = []\n",
    "for theta in range(2):\n",
    "    theta = theta / 4. * np.pi\n",
    "    for sigma in (2,3):\n",
    "        for frequency in (0.05, 0.25):\n",
    "            kernel = np.real(gabor_kernel(frequency, theta=theta,\n",
    "                                              sigma_x=sigma, sigma_y=sigma))\n",
    "            kernels.append(kernel)\n",
    "\n",
    "def gabor_feat(image):\n",
    "\n",
    "    feats = np.zeros((len(kernels), 3), dtype=np.double)\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered = ndi.convolve(image, kernel, mode='wrap')\n",
    "        feats[k, 0] = filtered.mean() # Média\n",
    "        feats[k, 1] = skew(filtered.flatten()) # Assimetria\n",
    "        feats[k, 2] = kurtosis(filtered.flatten()) # Curtose\n",
    "        _, (cH, cV, cD) = dwt2(filtered.T, 'db1')\n",
    "        r_feat = np.hstack([feats[0],feats[1],feats[2],feats[3]])\n",
    "\n",
    "    return r_feat \n",
    "\n",
    "\n",
    "\n",
    "# Momentos Zernike \n",
    "def ZernikeMoments(image):\n",
    "    gray = image\n",
    "    rows, cols = gray.shape\n",
    "    radius = cols//2 if rows > cols else rows//2\n",
    "    zernike = mahotas.features.zernike_moments(gray,radius)\n",
    "    return zernike    \n",
    "\n",
    "\n",
    "# Histogram of Oriented Gradients (HOG)\n",
    "def fd_hog_gradients(image):\n",
    "\n",
    "    fd, hog_image = feature.hog(image, orientations=8, pixels_per_cell=(128, 128),cells_per_block=(2, 2),\n",
    "                                transform_sqrt=True , block_norm=\"L1\",visualize=True)\n",
    "    return fd\n",
    "\n",
    "\n",
    "# LBP - Local Binary Pattern \n",
    "radius = 8\n",
    "numPoints = 64\n",
    "def describeLBP(image, eps=1e-7):\n",
    "    lbp = feature.local_binary_pattern(image,numPoints,radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, numPoints + 3),range=(0, numPoints + 2))\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250dd89e",
   "metadata": {
    "id": "250dd89e"
   },
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36f54b",
   "metadata": {
    "id": "fd36f54b"
   },
   "outputs": [],
   "source": [
    "def load_path(path):\n",
    "    labels_ = os.listdir(path)\n",
    "    features = []\n",
    "    labels   = []\n",
    "    for i, label in enumerate(labels_):\n",
    "        cur_path = path + \"/\" + label \n",
    "        for image_path in glob.glob(cur_path + \"/*\"):\n",
    "            img = cv2.imread(image_path)\n",
    "            image = cv2.resize(img, (256,256))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            image2 = image/255\n",
    "            lbp = describeLBP(image2) # LBP\n",
    "            hog = fd_hog_gradients(image2) # HOG \n",
    "            zernike = ZernikeMoments(image2) # Momentos de Zernike\n",
    "            gabor= gabor_feat(image2) # Filtros de Gabor \n",
    "\n",
    "            global_feature = np.hstack([hog,lbp, zernike, gabor])\n",
    "            features.append(global_feature)\n",
    "            labels.append(label)            \n",
    "        print (\"[INFO] completed label - \" + label)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "data, labels = load_data(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1aacda",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99150e91",
   "metadata": {
    "id": "99150e91"
   },
   "outputs": [],
   "source": [
    "svm = SVC(C=3, kernel='rbf', probability=True)\n",
    "mlp = MLPClassifier(activation='relu',max_iter=500,alpha=0.001,hidden_layer_sizes=(40,),learning_rate='constant')\n",
    "xgb = XGBClassifier(colsample_bytree= 1, max_depth=5, n_estimators=300, subsample= 0.6, seed=0)\n",
    "\n",
    "models = []\n",
    "models.append(('SVM', SVC(C=3, kernel='rbf')))\n",
    "models.append(('XGB', XGBClassifier(colsample_bytree= 1, max_depth=5, n_estimators= 100, subsample= 0.6, seed=0))) \n",
    "models.append(('MLP', MLPClassifier(activation='relu',max_iter=1000,alpha=0.01,hidden_layer_sizes=(40,40,40),learning_rate='constant')))\n",
    "models.append(('VOT', VotingClassifier(estimators = [('svm', svm),('mlp', mlp),('xgb', xgb)], voting='hard')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3136b2",
   "metadata": {
    "id": "cb3136b2"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebc8e3",
   "metadata": {
    "id": "839341f8"
   },
   "source": [
    "## Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec16922",
   "metadata": {
    "id": "3ec16922",
    "outputId": "0ca2b64e-b9eb-479f-d38b-837d6a392aec"
   },
   "outputs": [],
   "source": [
    "P0, A0, S0, E0, Fs0, TP0, TN0, FP0, FN0 = cv_train(models, data, labels, 10, 'None', 'scaler')\n",
    "results(P0, A0, S0, E0, Fs0, TP0, TN0, FP0, FN0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446c379",
   "metadata": {},
   "source": [
    "## Random Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "P3, A3, S3, E3, Fs3, TP3, TN3, FP3, FN3 = cv_train(models, data, labels, 10, 'random', 'scaler')\n",
    "results(P3, A3, S3, E3, Fs3, TP3, TN3, FP3, FN3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b854",
   "metadata": {},
   "source": [
    "## Near Miss Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cekYwcpVE3rp",
   "metadata": {
    "id": "cekYwcpVE3rp"
   },
   "outputs": [],
   "source": [
    "P2, A2, S2, E2, Fs2, TP2, TN2, FP2, FN2 = cv_train(models, data, labels, 10, 'nm', 'scaler')\n",
    "results(P2, A2, S2, E2, Fs2, TP2, TN2, FP2, FN2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd7c7a",
   "metadata": {},
   "source": [
    "## Cluster Centroid Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1, A1, S1, E1, Fs1, TP1, TN1, FP1, FN1 = cv_train(models, data, labels, 10, 'cluster', 'scaler')\n",
    "results(P1, A1, S1, E1, Fs1, TP1, TN1, FP1, FN1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed8ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a969c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classificacao_modelo_tradicional.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
